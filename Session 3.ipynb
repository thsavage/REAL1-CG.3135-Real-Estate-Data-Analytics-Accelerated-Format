{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REAL1-CG.3135: Real Estate Data Analytics (Intensive Format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Continued Discussion of Empirical Causality\n",
    "\n",
    "* Prior to the 1930s, there were few government-sponsored measures of economic activity.\n",
    "    * The unemployment rate in 1930 was 25%: this is at best a guess.\n",
    "\n",
    "\n",
    "\n",
    "* As the US and Europe slid into the Great Depression, policy makers lacked basic information.\n",
    "\n",
    "\n",
    "\n",
    "* In the US, the National Accounts were born in 1934 and greatly expanded during and after WWII.\n",
    "\n",
    "\n",
    "\n",
    "* At the same time, Alfred Cowles established the Cowles Commission for Research in Economics.\n",
    "\n",
    "\n",
    "\n",
    "* Cowles approach was a probabilistic framework to estimate systems of simultaneous equations to model an economy.\n",
    "\n",
    "\n",
    "\n",
    "* Ultimately would develop very large scale econometric models to examine a host of different economic variables. \n",
    "\n",
    "    * Main insight was a demonstrated bias of linear regression estimates derived from such models.\n",
    "    * Approach was found to be inadequate for policy evaluation (“Goodhart’s law” and “Lucas critique”).\n",
    "    \n",
    "\n",
    "\n",
    "### Goodhart's Conjecture\n",
    "\n",
    "* Goodhart “asserts that any economic relation tends to break down when used for policy purposes.”  (Wickens [2008].)\n",
    "    * Proposed relationships, economic or otherwise, are not structural in nature.\n",
    "    * Instead they sre derived from fundamental behavioral relationships (structural).\n",
    "    \n",
    "\n",
    "\n",
    "### Lucas' Critique\n",
    "\n",
    "* Lucas (1976) notes that individual decision rules affected by policy are driven by “deep structural parameters.” \n",
    "    * Decision rules and, therefore, decisions are contingent on the state of the system as it is.\n",
    "    * Change the system through policy, change the decision rule.\n",
    "    * Such changes may not be captured in non-structural models.\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "### Experimental Design: Natural Experiments (Freakonomics)\n",
    "\n",
    "> A natural experiment is an empirical study in which individuals (or clusters of individuals) exposed to the experimental and control conditions are determined by nature or by other factors outside the control of the investigators, yet the process governing the exposures arguably resembles random assignment.\n",
    "\n",
    "> Wikipedia\n",
    "\n",
    "* Examples\n",
    "    * **Natural crises**\n",
    "        * 1906 S.F. earthquake to examine the impact of stock changes (vacancy) on rent.\n",
    "        * Hurricane Sandy.\n",
    "    * **Lotteries** that truly randomize a group of individuals.  \n",
    "        * Vietnam draft in the U.S. as a means to explore the impacts of education on wages.\n",
    "        * Delay in schooling reduces wages (even if the same level of schooling is achieved).\n",
    "        * Randomized eligibility for mandatory military service in Argentina.  \n",
    "            * Actual conscription increases the likelihood of having a criminal record later in adulthood. \n",
    "            * Possible inference: Delayed entry to the labor market has adverse implications in later labor market outcomes.\n",
    "        * Recent paper on the impact of rent control on quality of housing stock.\n",
    "    * **Jurisdictional boundaries** over which policies are different.\n",
    "        * Different minimum wage laws (New Jersey and Pennsylvania) to examine the impact of minimum wages on employment levels.\n",
    "        * North v. South Korea.\n",
    "    * **Same individuals** faced with exogenous changes (though doing the same thing).\n",
    "        * Tim in the classroom versus Tim online.\n",
    "        \n",
    "\n",
    "\n",
    "### Will the Explosion of Data Help?\n",
    "* Perhaps, but it depends on understanding algorithms.\n",
    "* And understanding DGPs.\n",
    "* In the meantime, let's move up Pearl's Ladder: bivariate to multivariate regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression with Multiple Features and the Valid Application of Diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is trivial to extend the single-feature linear model to a linear model that simultaneously incorporates multiple features.  The interpretation of the results of a statistical model that uses multiple features is the same the interpretation of the partial derivative from the calculus of many variables: the effect of a small change in a particular feature on a label (or outcome).  \n",
    "\n",
    "* A model with $K$ features, $x_{ik}$ and label $y_i$:\n",
    "\n",
    "* $y_i=\\sum_{k=1}^Kx_{ik}\\cdot\\beta_k+\\epsilon_i = x_i^\\prime \\beta + \\epsilon_i$\n",
    "\n",
    "* The $K$ features $x_{ik}$ influence the label $y_i$ through the $K$-vector, $\\beta$, which we estimate statistically.  A specific partial derivative interpretation.\n",
    "\n",
    "* ${\\displaystyle \\frac{\\partial E(y_i)}{\\partial x_{ik}}=\\beta_k}$\n",
    "\n",
    "* For those interested in ancient history: Frisch–Waugh–Lovell theorem.  One can applied the basic principle from multivariate calculus: Holding everything else constant, what is the impact of a feature on an outcome of interest.\n",
    "\n",
    "**Bottom line is simple**: Fit the linear model with multiple features.  The basic approach to hypothesis testing remains unchanged.  The challenge is the interpretation of the results and the valid application of regression diagnostics.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goodness of Fit: Abuse and Misuse\n",
    "\n",
    "* The R$^2$ metric (poor thing)\n",
    "\n",
    "* Different statisical computing environments largely produce the same regression ouput, formatted differently.  This information is typically used for 'regression diagnosgics.'  We have begun to cover regression coefficients and their interpretation, as well as the use of standard errors, t values, and confidence intervals for hypothesis testing. \n",
    "\n",
    "* The R$^2$ **goodness of fit** metric is a frequently-cited regression diagnostic.  If a linear regression uses a constant (which should be included in practice), the R$^2$ is bounded between 0 and 1.  It measures the share of the variation in $y$ explained by the variation in the features used in a model.  Given this definition, 'bigger is better' is the first place that people go to evaluate the quality of the model, which is unwarranted.  \n",
    "\n",
    "> \"However, it can still be challenging to determine what is a good R$^2$ value, and in general, this will depend on the application.  For instance, in certain problems in physics, we may know that the data truly comes from a linear model with a small residual error.  In this case, we would expect to see an R$^2$ value that is extremely close to 1, and a substantially smaller R$^2$ might indicate serious problems with the experiment in which the data were generated.  On the other hand, in typical application in biology, pyschology, marketing and other domains, the linear model is at best an extremely rough approximation to the data, and residual errors due to other unmeasured factors are often very large.  In this setting, we would expect only a very small proportion of the variance in the response to be explained by the predictor, and an R$^2$ value well below 0.1 might be more realistic.\"  \n",
    "Trevor Hastie, Robert Tibshirani, et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "* My R$^2$ Is One!  The Best Ever!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The example re-inforces the point above from Professors Hastie and Tibshirani to consider your application (or use case).  In processes that change slowly, the predictive power of a model (or representation) should be very good, reflected in the R$^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Diagnostics to Assess Model Quality\n",
    "\n",
    "Adjusted R$^2$: A metric that captures the penalty in the use of a large number of features with little explanatory power.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is evidence of omitted variable bias (sometimes called the \"collinearity problem\")\n",
    "* Failing to include land_size has biased up the measured effect of unit_size because the two features are positively correlated.\n",
    "* The two features, however, have independent effects on sales prices.\n",
    "* In this example, we can compare the R-squared measures across the two models because one is nested in the other.  \n",
    "* We see that the R-squared rises from 0.302 to 0.387, indicating a considerable improvement in the fit of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More features\n",
    "* Now let's examine what happens when we account for the age of the dwelling at the date of sale.\n",
    "* Thoughts about how age might affect sales prices?\n",
    "* Negative impact: old houses (of equal size) have lower sales prices.\n",
    "* Note, however, that there is little impact on the effects of the other features when we add age to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indicator Variables: Supervised to Semi-supervised\n",
    "\n",
    "* Indicator variables capture potential *discontinuities* in a function.\n",
    "* **Todt Hill is an upscale area in Staten Island.**\n",
    "* Suppose we want to capture this feature of the data, which we can do using the indicator \"todt\". \n",
    "* 3.574e+05 = 357,400 dollar premium in Todt Hill for any randomly chosen house."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing Non-Linearities to the Linear Model\n",
    "\n",
    "* Suppose we want to consider the potential of non-linearities in $y=f(x)$.\n",
    "* We can use the linear model to do so, but must consider the calculus behind it.\n",
    "* One conjecture is that age has a diminishing effect on sales prices.\n",
    "* How to capture this conjecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Interpret?\n",
    "\n",
    "A model with $K$ features, $x_{ik}$ and label $y_i$: $y_i=\\sum_{k=1}^Kx_{ik}\\cdot\\beta_k+\\epsilon_i = x_i^\\prime \\beta + \\epsilon_i$\n",
    "\n",
    "$\\frac{\\partial{E(y_i})}{\\partial{x_{ik}}}=\\hat{\\beta_k}$\n",
    "\n",
    "$\\frac{\\partial{E(\\text{sales price}})}{\\partial{\\text{age}}}=\\hat{\\beta_\\text{age}} + 2\\cdot\\hat{\\beta_\\text{age2}}\\cdot{\\text{age}} = 997 - 2\\cdot17\\cdot\\text{age} = 997 - 34\\cdot\\text{age}$\n",
    "\n",
    "The average age of a house in our data is 36 years, so $997 - 34*36 = 997 - 1224 = -227$.  Therefore, when a house hits its average age, its value is declining every year.  \n",
    "\n",
    "Indeed, we can solve the simple algebra problem, $997 - 34*age = 0$, for age to obtain $\\text{age}\\approx29$.  For the first 29 years, house prices on average rise for each year, and then begin to decline for subsequent years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's examine these results.  \n",
    "* Prices appear to be linear in unit size.\n",
    "* Prices appear to be quadratic in land_size: a positive but diminishing effect.  At what point does the positive effect disappear.\n",
    "* Prices appear to be quadatric in age: initially rising and then falling in age as houses reach the sample's average age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering: Elasticities\n",
    "* It may be of use to engineer your features so that results are unit free.\n",
    "* The interpretation is: for at 1% change in the feature, what is the % change in the label.\n",
    "* This can be achieved by tranforming the feature and labels using logarithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's examine these results.\n",
    "\n",
    "* A 10% change in unit size increases sales price by 3.4%.\n",
    "* A 10% change in land size increases sales price by 2.6%.\n",
    "* A 10% change in age decreases sales prices by 0.5%.\n",
    "* Prices in Todt Hill are about 44% higher holding all else constant.\n",
    "* Is this model directly comparable to the one above?\n",
    "* No because we non-linearly transformed both the label and the features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
